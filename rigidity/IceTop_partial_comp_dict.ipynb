{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3ccab30",
   "metadata": {},
   "source": [
    "# IceTop Rigidity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfa16f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063c6175",
   "metadata": {},
   "source": [
    "## Miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95d6387-9e82-450d-b01c-a4b21aa9b10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os, sys, glob, pickle, tables\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pandas import DataFrame\n",
    "\n",
    "# pip install simweights <--- run this once to install the package\n",
    "# then replace <username> with your username and <version> with your Python version\n",
    "sys.path.append('/home/<username>/.local/lib/python3.<version>/site-packages')\n",
    "import simweights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "673ddfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to h5 files\n",
    "PATHS = ['/data/ana/CosmicRay/IceTop_level3/sim/IC86.2012/SIBYLL2.1/p/12360_v1s/h5files/*.h5',\n",
    "'/data/ana/CosmicRay/IceTop_level3/sim/IC86.2012/SIBYLL2.1/He/12630_v1s/h5files/*.h5',\n",
    "'/data/ana/CosmicRay/IceTop_level3/sim/IC86.2012/SIBYLL2.1/O/12631_v1s/h5files/*.h5',\n",
    "'/data/ana/CosmicRay/IceTop_level3/sim/IC86.2012/SIBYLL2.1/Fe/12362_v1s/h5files/*.h5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82dea77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define important functions\n",
    "def weighting(path):\n",
    "    filelist = glob.glob(path)\n",
    "\n",
    "    for filename in filelist:\n",
    "        file_obj = tables.open_file(filename, 'r')\n",
    "    \n",
    "        if weighter is None:\n",
    "            weighter = simweights.IceTopWeighter(file_obj)\n",
    "        else:\n",
    "            weighter += simweights.IceTopWeighter(file_obj)\n",
    "    return weighter\n",
    "\n",
    "def weighted_quantiles(values, weights, quantiles=0.5):\n",
    "    i = np.argsort(values)\n",
    "    c = np.cumsum(weights[i])\n",
    "    return values[i[np.searchsorted(c, np.array(quantiles) * c[-1])]]\n",
    "\n",
    "def weighted_percentile(data, weights, percentile):\n",
    "    \"\"\"\n",
    "    Compute the weighted percentile of a dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: array-like, the data values.\n",
    "    - weights: array-like, same length as data.\n",
    "    - percentile: float between 0 and 100.\n",
    "    \n",
    "    Returns:\n",
    "    - The weighted percentile value.\n",
    "    \"\"\"\n",
    "    data = np.asarray(data)\n",
    "    weights = np.asarray(weights)\n",
    "    \n",
    "    # Sort data and weights by data\n",
    "    sorted_indices = np.argsort(data)\n",
    "    data_sorted = data[sorted_indices]\n",
    "    weights_sorted = weights[sorted_indices]\n",
    "\n",
    "    # Compute the cumulative sum of weights\n",
    "    cumulative_weights = np.cumsum(weights_sorted)\n",
    "    normalized_weights = cumulative_weights / cumulative_weights[-1]  # normalize to 1\n",
    "\n",
    "    # Find where the normalized cumulative weight exceeds the desired percentile\n",
    "    return np.interp(percentile / 100, normalized_weights, data_sorted) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b81daa7d-0bfd-48d0-96da-917488f9a510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the SIBYLL2.1 particle sims\n",
    "weighter = None\n",
    "\n",
    "# Checks to see if the pickle exists, otherwise prepares weighter\n",
    "if os.path.isfile('pickles/energy.pkl'):\n",
    "    with open('pickles/energy.pkl', 'rb') as file:\n",
    "        primary_energy = pickle.load(file)\n",
    "else:\n",
    "    for path in PATHS:\n",
    "        if weighter == None:\n",
    "            weighter = weighting(path)\n",
    "        else:\n",
    "            weighter += weighting(path)\n",
    "\n",
    "if os.path.isfile('pickles/hits.pkl'):\n",
    "    with open('pickles/hits.pkl', 'rb') as file:\n",
    "        hits = pickle.load(file)\n",
    "elif not weighter == None:\n",
    "    for path in PATHS:\n",
    "        if weighter == None:\n",
    "            weighter = weighting(path)\n",
    "        else:\n",
    "            weighter += weighting(path)\n",
    "\n",
    "if os.path.isfile('pickles/particle_type.pkl'):\n",
    "    with open('pickles/particle_type.pkl', 'rb') as file:\n",
    "        particle_type = pickle.load(file)\n",
    "elif not weighter == None:\n",
    "    for path in PATHS:\n",
    "        if weighter == None:\n",
    "            weighter = weighting(path)\n",
    "        else:\n",
    "            weighter += weighting(path)\n",
    "\n",
    "if os.path.isfile('pickles/zenith.pkl'):\n",
    "    with open('pickles/zenith.pkl', 'rb') as file:\n",
    "        zenith = pickle.load(file)\n",
    "elif not weighter == None:\n",
    "    for path in PATHS:\n",
    "        if weighter == None:\n",
    "            weighter = weighting(path)\n",
    "        else:\n",
    "            weighter += weighting(path)\n",
    "\n",
    "if os.path.isfile('pickles/reco_pass.pkl'):\n",
    "    with open('pickles/reco_pass.pkl', 'rb') as file:\n",
    "        reco_pass = pickle.load(file)\n",
    "elif not weighter == None:\n",
    "    for path in PATHS:\n",
    "        if weighter == None:\n",
    "            weighter = weighting(path)\n",
    "        else:\n",
    "            weighter += weighting(path)\n",
    "\n",
    "if os.path.isfile('pickles/Hweights.pkl'):\n",
    "    with open('pickles/Hweights.pkl', 'rb') as file:\n",
    "        Hweights = pickle.load(file)\n",
    "elif not weighter == None:\n",
    "    for path in PATHS:\n",
    "        if weighter == None:\n",
    "            weighter = weighting(path)\n",
    "        else:\n",
    "            weighter += weighting(path)\n",
    "                \n",
    "if os.path.isfile('pickles/Gweights.pkl'):\n",
    "    with open('pickles/Gweights.pkl', 'rb') as file:\n",
    "        Gweights = pickle.load(file)\n",
    "elif not weighter == None:\n",
    "    for path in PATHS:\n",
    "        if weighter == None:\n",
    "            weighter = weighting(path)\n",
    "        else:\n",
    "            weighter += weighting(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38d6a19c-b653-4e46-875d-7b9a91ab0c3d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If there are missing pkl files, load them with weighter\n",
    "if not os.path.isfile('pickles/energy.pkl'):\n",
    "    primary_energy = weighter.get_column('MCPrimary', 'energy')\n",
    "\n",
    "if not os.path.isfile('pickles/particle_type.pkl'):\n",
    "    particle_type = weighter.get_column('MCPrimary', 'type')\n",
    "    \n",
    "if not os.path.isfile('pickles/zenith.pkl'):\n",
    "    zenith = weighter.get_column('MCPrimary', 'zenith')\n",
    "\n",
    "if not os.path.isfile('pickles/hits.pkl'):\n",
    "    hits = weighter.get_column('IceTopHLCSeedRTPulses_SnowUnAttenuated_info', 'nstrings')\n",
    "\n",
    "if not os.path.isfile('pickles/reco_pass.pkl'):\n",
    "    reco_pass = weighter.get_column('IT73AnalysisIceTopQualityCuts', 'IceTop_reco_succeeded')\n",
    "        \n",
    "if not os.path.isfile('pickles/Hweights.pkl'):\n",
    "    # (p, He, N, Al, Fe) version of this model.\n",
    "    fluxH = simweights.GaisserH4a_IT()\n",
    "\n",
    "    # Get the weights by passing the flux to the weighter\n",
    "    Hweights = weighter.get_weights(fluxH)\n",
    "\n",
    "if not os.path.isfile('pickles/Gweights.pkl'):\n",
    "    fluxG = simweights.GlobalSplineFit_IT()\n",
    "\n",
    "    Gweights = weighter.get_weights(fluxG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21a673f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets up quality cut (zenith < 55º and the reconstruction succeeded)\n",
    "quality_cut = np.logical_and(zenith < np.radians(55), reco_pass.astype(bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c372e3e-71a6-4032-97ea-8c1ecbe350a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary set-ups\n",
    "# Different compositions\n",
    "CUTS = {\n",
    "    'proton': particle_type==2.21200000e+03,\n",
    "    'helium' : particle_type==1.00002004e+09,\n",
    "    'oxygen': particle_type==1.00008016e+09,\n",
    "    'iron': particle_type==1.00026056e+09,\n",
    "    'true': np.tile(True, len(primary_energy))\n",
    "}\n",
    "# amu of different comps\n",
    "A = {\n",
    "    'proton': 1.0073,\n",
    "    'helium': 4.0026,\n",
    "    'oxygen': 16,\n",
    "    'iron': 55.845  \n",
    "}\n",
    "# Number of protons for different comps\n",
    "Z = {\n",
    "    'proton': 1,\n",
    "    'helium': 2,\n",
    "    'oxygen': 8,\n",
    "    'iron': 26  \n",
    "}\n",
    "# IceTop Tiers\n",
    "'''\n",
    "Tier 1: 2011-14 is 3≤n<5\n",
    "Tier 2: 2011 is 5≤n<10; 2012-2013 is 5≤n<9; 2014 is 5≤n<8\n",
    "Tier 3: 2011 is 10≤n<14, from 2012-13 9≤n<16; 2014-15 is 8≤n<15; \n",
    "Tier 4: 2011 is 14≤n, 2012-13 16≤n; 2014-15 is 15≤n; 2016-17 is 14≤n; 2018-19 is 13≤n; 2020-21 is 12≤n\n",
    "'''\n",
    "TIERS = {\n",
    "    'Tier 3': np.logical_and(8<=hits, hits<15, zenith<np.radians(55)),\n",
    "    'Tier 4': np.logical_and(15<=hits, quality_cut)\n",
    "}\n",
    "# Graph colors by comp\n",
    "COLORS = {\n",
    "    'true' : 'black',\n",
    "    'proton': 'red',\n",
    "    'helium': 'orange',\n",
    "    'oxygen': 'purple',\n",
    "    'iron': 'blue'\n",
    "}\n",
    "# Graph labels by comp\n",
    "LABEL = {\n",
    "    'true' : 'Data',\n",
    "    'proton': 'p',\n",
    "    'helium': 'He',\n",
    "    'oxygen': 'O',\n",
    "    'iron': 'Fe'\n",
    "}\n",
    "# Weights\n",
    "SIMS = {\n",
    "    'H4a': Hweights,\n",
    "    'GSF': Gweights\n",
    "}\n",
    "# Flux from histogram\n",
    "FLUX = {\n",
    "    'true'  : {'Tier 1': {'H4a': np.arange(5, 8.5, .1), 'GSF': np.arange(5, 8.5, .1)},\n",
    "               'Tier 2': {'H4a': np.arange(5, 8.5, .1), 'GSF': np.arange(5, 8.5, .1)},\n",
    "               'Tier 3': {'H4a': np.arange(5, 8.5, .1), 'GSF': np.arange(5, 8.5, .1)},\n",
    "               'Tier 4': {'H4a': np.arange(5, 8.5, .1), 'GSF': np.arange(5, 8.5, .1)},},\n",
    "    'proton': {'Tier 1': {'H4a': np.arange(5, 8.5, .1), 'GSF': np.arange(5, 8.5, .1)},\n",
    "               'Tier 2': {'H4a': np.arange(5, 8.5, .1), 'GSF': np.arange(5, 8.5, .1)},\n",
    "               'Tier 3': {'H4a': np.arange(5, 8.5, .1), 'GSF': np.arange(5, 8.5, .1)},\n",
    "               'Tier 4': {'H4a': np.arange(5, 8.5, .1), 'GSF': np.arange(5, 8.5, .1)},},\n",
    "    'helium': {'Tier 1': {'H4a': np.arange(5, 8.5, .1), 'GSF': np.arange(5, 8.5, .1)},\n",
    "               'Tier 2': {'H4a': np.arange(5, 8.5, .1), 'GSF': np.arange(5, 8.5, .1)},\n",
    "               'Tier 3': {'H4a': np.arange(5, 8.5, .1), 'GSF': np.arange(5, 8.5, .1)},\n",
    "               'Tier 4': {'H4a': np.arange(5, 8.5, .1), 'GSF': np.arange(5, 8.5, .1)},},\n",
    "    'oxygen': {'Tier 1': {'H4a': np.arange(5, 8.5, .1), 'GSF': np.arange(5, 8.5, .1)},\n",
    "               'Tier 2': {'H4a': np.arange(5, 8.5, .1), 'GSF': np.arange(5, 8.5, .1)},\n",
    "               'Tier 3': {'H4a': np.arange(5, 8.5, .1), 'GSF': np.arange(5, 8.5, .1)},\n",
    "               'Tier 4': {'H4a': np.arange(5, 8.5, .1), 'GSF': np.arange(5, 8.5, .1)},},\n",
    "    'iron'  : {'Tier 1': {'H4a': np.arange(5, 8.5, .1), 'GSF': np.arange(5, 8.5, .1)},\n",
    "               'Tier 2': {'H4a': np.arange(5, 8.5, .1), 'GSF': np.arange(5, 8.5, .1)},\n",
    "               'Tier 3': {'H4a': np.arange(5, 8.5, .1), 'GSF': np.arange(5, 8.5, .1)},\n",
    "               'Tier 4': {'H4a': np.arange(5, 8.5, .1), 'GSF': np.arange(5, 8.5, .1)},}\n",
    "}\n",
    "# Histogram bins\n",
    "BINS = {\n",
    "    'true'  : {'Tier 1': {'H4a': np.arange(5, 8.5, .1), 'GSF': np.arange(5, 8.5, .1)},\n",
    "               'Tier 2': {'H4a': np.arange(5, 8.5, .1), 'GSF': np.arange(5, 8.5, .1)},\n",
    "               'Tier 3': {'H4a': np.arange(5, 8.5, .1), 'GSF': np.arange(5, 8.5, .1)},\n",
    "               'Tier 4': {'H4a': np.arange(5, 8.5, .1), 'GSF': np.arange(5, 8.5, .1)},},\n",
    "    'proton': {'Tier 1': {'H4a': np.arange(5, 8.5, .1), 'GSF': np.arange(5, 8.5, .1)},\n",
    "               'Tier 2': {'H4a': np.arange(5, 8.5, .1), 'GSF': np.arange(5, 8.5, .1)},\n",
    "               'Tier 3': {'H4a': np.arange(5, 8.5, .1), 'GSF': np.arange(5, 8.5, .1)},\n",
    "               'Tier 4': {'H4a': np.arange(5, 8.5, .1), 'GSF': np.arange(5, 8.5, .1)},},\n",
    "    'helium': {'Tier 1': {'H4a': np.arange(5, 8.5, .1), 'GSF': np.arange(5, 8.5, .1)},\n",
    "               'Tier 2': {'H4a': np.arange(5, 8.5, .1), 'GSF': np.arange(5, 8.5, .1)},\n",
    "               'Tier 3': {'H4a': np.arange(5, 8.5, .1), 'GSF': np.arange(5, 8.5, .1)},\n",
    "               'Tier 4': {'H4a': np.arange(5, 8.5, .1), 'GSF': np.arange(5, 8.5, .1)},},\n",
    "    'oxygen': {'Tier 1': {'H4a': np.arange(5, 8.5, .1), 'GSF': np.arange(5, 8.5, .1)},\n",
    "               'Tier 2': {'H4a': np.arange(5, 8.5, .1), 'GSF': np.arange(5, 8.5, .1)},\n",
    "               'Tier 3': {'H4a': np.arange(5, 8.5, .1), 'GSF': np.arange(5, 8.5, .1)},\n",
    "               'Tier 4': {'H4a': np.arange(5, 8.5, .1), 'GSF': np.arange(5, 8.5, .1)},},\n",
    "    'iron'  : {'Tier 1': {'H4a': np.arange(5, 8.5, .1), 'GSF': np.arange(5, 8.5, .1)},\n",
    "               'Tier 2': {'H4a': np.arange(5, 8.5, .1), 'GSF': np.arange(5, 8.5, .1)},\n",
    "               'Tier 3': {'H4a': np.arange(5, 8.5, .1), 'GSF': np.arange(5, 8.5, .1)},\n",
    "               'Tier 4': {'H4a': np.arange(5, 8.5, .1), 'GSF': np.arange(5, 8.5, .1)},}\n",
    "}\n",
    "# Linestyle by weights\n",
    "LINESTYLE = {\n",
    "    'H4a': None,\n",
    "    'GSF': '--'\n",
    "}\n",
    "# Dictionary for total flux across compositions for each Tier and weight, and for total flux times log(Z) across compositions for each Tier and weight\n",
    "TOTALS = {\n",
    "    'numerator'  : {'Tier 3': {'H4a': np.zeros(nbins), 'GSF': np.zeros(nbins)},\n",
    "                    'Tier 4': {'H4a': np.zeros(nbins), 'GSF': np.zeros(nbins)}},\n",
    "    'denominator': {'Tier 3': {'H4a': np.zeros(nbins), 'GSF': np.zeros(nbins)},\n",
    "                    'Tier 4': {'H4a': np.zeros(nbins), 'GSF': np.zeros(nbins)}},\n",
    "}\n",
    "# Table for partial compositions, ln(A), and mean log of rigidity, energy, and Z for each Tier and weight\n",
    "TABLE = {\n",
    "        'H4a': {'Tier 3': {'proton part': 0, 'helium part': 0, 'oxygen part': 0, 'iron part': 0, 'ln(A)': 0, '<log(R)>': 0, '<log(E)>': 0, '<log(Z)>': 0},\n",
    "                'Tier 4': {'proton part': 0, 'helium part': 0, 'oxygen part': 0, 'iron part': 0, 'ln(A)': 0, '<log(R)>': 0, '<log(E)>': 0, '<log(Z)>': 0}},\n",
    "        'GSF': {'Tier 3': {'proton part': 0, 'helium part': 0, 'oxygen part': 0, 'iron part': 0, 'ln(A)': 0, '<log(R)>': 0, '<log(E)>': 0, '<log(Z)>': 0},\n",
    "                'Tier 4': {'proton part': 0, 'helium part': 0, 'oxygen part': 0, 'iron part': 0, 'ln(A)': 0, '<log(R)>': 0, '<log(E)>': 0, '<log(Z)>': 0}}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29077159",
   "metadata": {},
   "source": [
    "## $\\log_{10}$ weighted counts vs. $\\log_{10}$ Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4271ee3-c328-4f84-8102-7d01954e8dfc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare the graphs\n",
    "ncols = len(TIERS)\n",
    "fig, axs = plt.subplots(figsize=(13 * ncols, 8), ncols=ncols)\n",
    "\n",
    "for tier, tier_cut, ax in zip(TIERS.keys(), TIERS.values(), axs):\n",
    "    # Print Tier for table\n",
    "    print(tier)\n",
    "    print('--------------------------------------------------')\n",
    "    \n",
    "    for weight_name, weights in SIMS.items():\n",
    "        # Print weights for table\n",
    "        print(weight_name)\n",
    "\n",
    "        for comp, comp_cut in CUTS.items():\n",
    "            # Combine cuts\n",
    "            combined_cut = np.logical_and(comp_cut, tier_cut)\n",
    "\n",
    "            # Graph primary energy\n",
    "            FLUX[comp][tier][weight_name], BINS[comp][tier][weight_name], patches1 = ax.hist(\n",
    "            np.log10(primary_energy[combined_cut]), weights=weights[combined_cut],\n",
    "            bins=nbins, linestyle=LINESTYLE[weight_name], log=True, label=f'{LABEL[comp]} ({weight_name})', histtype='step', color=COLORS[comp])\n",
    "\n",
    "            # Print median energy and its first sigma\n",
    "            if comp=='proton' or comp=='iron' or comp=='true':\n",
    "                print(f'    {comp}')\n",
    "                print(f'        Median: {round(weighted_quantiles(primary_energy[combined_cut]/1000000, weights[combined_cut]), 2)} PeV')\n",
    "                print(f'        68%: {round(weighted_percentile(primary_energy[combined_cut]/1000000, weights[combined_cut], 16), 2)}-{round(weighted_percentile(primary_energy[combined_cut]/1000000, Hweights[combined_cut], 84), 2)} PeV')\n",
    "                print()\n",
    "\n",
    "    # Label axes and add legend and title\n",
    "    ax.set_xlabel('log10(Energy)')\n",
    "    ax.set_ylabel('Rates (Hz)')\n",
    "    ax.set_title(f'Log10 Energy vs Log 10 Weighted Counts for {tier}')\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520cb514",
   "metadata": {},
   "source": [
    "## Mean Atomic Charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb03ebe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(13 * ncols, 8), ncols=ncols)\n",
    "\n",
    "for tier, ax in zip(TIERS, axs):    \n",
    "    for weight_name in SIMS:\n",
    "        for comp in CUTS:\n",
    "            if not comp=='true':\n",
    "                # Sum flux at for each comp, Tier and weight times the number of protons for the comp\n",
    "                TOTALS['numerator'][tier][weight_name] += FLUX[comp][tier][weight_name] * np.log10(Z[comp])\n",
    "\n",
    "                # Sum flux at for each comp, Tier and weight\n",
    "                TOTALS['denominator'][tier][weight_name] += FLUX[comp][tier][weight_name]\n",
    "\n",
    "        # Calculate <Z>\n",
    "        meanZ = TOTALS['numerator'][tier][weight_name] / TOTALS['denominator'][tier][weight_name]\n",
    "\n",
    "        # Plot <Z> vs. energy\n",
    "        ax.plot(BINS['true'][tier][weight_name][:-1], meanZ, label=weight_name, linestyle=LINESTYLE[weight_name])\n",
    "\n",
    "    ax.set_xlabel('log10(Energy/GeV)')\n",
    "    ax.set_ylabel('Mean log10(Z)')\n",
    "    ax.set_title(f'Mean log(Z) vs. Energy for {tier}')\n",
    "\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7605d800",
   "metadata": {},
   "source": [
    "## Particle Fraction vs. Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c674cf-fe2c-445f-843f-4fad0cf63666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Particle Fraction vs. Energy\n",
    "fig, axs = plt.subplots(figsize=(13 * ncols, 8), ncols=ncols)\n",
    "\n",
    "for tier, ax in zip(TIERS, axs):\n",
    "    for weight_name in SIMS:\n",
    "        for comp in CUTS:\n",
    "            # Plot fractional composition\n",
    "            if not comp=='true':\n",
    "                ax.plot(BINS[comp][tier][weight_name][:-1], FLUX[comp][tier][weight_name] / TOTALS['denominator'][tier][weight_name],\n",
    "                label=f'{LABEL[comp]} ({weight_name})', linestyle=LINESTYLE[weight_name], color=COLORS[comp])\n",
    "\n",
    "    ax.set_xlabel('log10(Energy/GeV)')\n",
    "    ax.set_ylabel('Fraction of Particles')\n",
    "    ax.set_title(f'Particle Fraction vs. Energy for {tier}')\n",
    "\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c4af8e",
   "metadata": {},
   "source": [
    "## Table of percentage of particles, $\\ln(A)$, and mean $\\log_{10}$ of Rigidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740607d0-f921-4c74-b7e8-3d140f0c0c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table of the overall percentage of particles, ln(A), and mean log of rigidity\n",
    "for weight_name, weights in SIMS.items():\n",
    "    # Print weight name for data table\n",
    "    print(weight_name)\n",
    "    print()\n",
    "\n",
    "    for tier, tier_cut in TIERS.items():\n",
    "        # Start ln_A at zero\n",
    "        ln_A = 0\n",
    "\n",
    "        # Combine tier and quality cuts\n",
    "        combined_cut = tier_cut\n",
    "\n",
    "        for comp in CUTS:\n",
    "            if not comp=='true':\n",
    "                \n",
    "                # Save the partial compositions to the table\n",
    "                TABLE[weight_name][tier][f'{comp} part'] = round(np.mean(FLUX[comp][tier][weight_name]) / np.mean(TOTALS['denominator'][tier][weight_name]), 3)\n",
    "\n",
    "                # Calculate the mean ln(A) with partial compositions\n",
    "                ln_A += TABLE[weight_name][tier][f'{comp} part'] * np.log(A[comp])\n",
    "\n",
    "        # Save ln(A) to the table\n",
    "        TABLE[weight_name][tier]['ln(A)'] = round(ln_A, 3)\n",
    "        \n",
    "        # Calculate mean log E (Scaled to TeV), mean log Z, and finally mean log rigidity\n",
    "        TABLE[weight_name][tier]['<log(E)>'] = round(np.average(np.log10(primary_energy)[combined_cut] - 3, weights=weights[combined_cut]), 3)\n",
    "        TABLE[weight_name][tier]['<log(Z)>'] = round(np.mean(TOTALS['numerator'][tier][weight_name]) / np.mean(TOTALS['denominator'][tier][weight_name]), 3)\n",
    "        TABLE[weight_name][tier]['<log(R)>'] = TABLE[weight_name][tier]['<log(E)>'] - TABLE[weight_name][tier]['<log(Z)>']\n",
    "\n",
    "    # Print out the table for that weight\n",
    "    print(DataFrame(TABLE[weight_name]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bafe5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rate vs Rigidity\n",
    "fig, axs = plt.subplots(figsize = (13 * ncols, 8), ncols=ncols)\n",
    "\n",
    "for tier, tier_cut, ax in zip(TIERS.keys(), TIERS.values(), axs):\n",
    "    for weight_name, weights in SIMS.items():\n",
    "\n",
    "        for comp, comp_cut in CUTS.items():\n",
    "            combined_cut = np.logical_and(comp_cut, tier_cut, quality_cut)\n",
    "            rigidity = np.log10(primary_energy[combined_cut]) - 3 - np.mean(TOTALS['numerator'][tier][weight_name]) / np.mean(TOTALS['denominator'][tier][weight_name])\n",
    "            # Graph rate vs. rigidity\n",
    "            ax.hist(rigidity,weights=weights[combined_cut], bins=nbins, linestyle=LINESTYLE[weight_name], log=True,\n",
    "                    label=f'{LABEL[comp]} ({weight_name})', histtype='step', color=COLORS[comp])\n",
    "    \n",
    "    ax.set_xlabel('Rigidity')\n",
    "    ax.set_ylabel('Rate (Hz)')\n",
    "    ax.set_title(f'Rate vs Rigidity for {tier}')\n",
    "    ax.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-v4.3.0: v1.12.1",
   "language": "shell",
   "name": "py3-v4.3.0_v1.12.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
